Day 1 of learning:
------------------
Offical documentation:
----------------------
https://joblib.readthedocs.io/en/latest/

Joblib:
-------
Introduction:
-------------
Joblib is a set of tools to provide lightweight pipelining in Python. In particular:
	1.	Transparent disk-caching of functions and lazy re-evaluation (memoize pattern)
	2.	Easy simple parallel computing

	Joblib is optimized to be fast and robust on large data in particular and has specific optimizations for numpy arrays. It is BSD-licensed.

Vision:
-------
The vision is to provide tools to easily achieve better performance and reproducibility when working with long running jobs.

	1.	Avoid computing the same thing twice: code is often rerun again and again, for instance when prototyping computational-heavy jobs, 
but hand-crafted solutions to alleviate this issue are error-prone and often lead to unreproducible results.
	2.	Persist to disk transparently: efficiently persisting arbitrary objects containing large data is hard. 
	Joblib’s caching mechanism avoids hand-written persistence and implicitly links the file on disk to the execution context of the original Python object.
	Joblib’s persistence is good for resuming an application status or computational job.
	Joblib addresses these problems while leaving your code and your flow control as unmodified as possible.

Main features:
--------------
Transparent and fast disk-caching of output value: 
	1.	a memoize or make-like functionality for Python functions that works well for arbitrary Python objects, including very large numpy arrays. 
	2.	Separate persistence and flow-execution logic from domain logic or algorithmic code by the operations as a inputs and outputs: Python functions. 
	3.	Joblib can save their computation to disk and rerun it only if necessary:

Sample Example:
---------------	
	
>>> from joblib import Memory
>>> cachedir = 'your_cache_dir_goes_here'
>>> mem = Memory(cachedir)
>>> import numpy as np
>>> a = np.vander(np.arange(3)).astype(np.float)
>>> square = mem.cache(np.square)
>>> b = square(a)                                   
________________________________________________________________________________
[Memory] Calling square...
square(array([[0., 0., 1.],
       [1., 1., 1.],
       [4., 2., 1.]]))
___________________________________________________________square - 0...s, 0.0min

>>> c = square(a)
>>> # The above call did not trigger an evaluation
Embarrassingly parallel helper: to make it easy to write readable parallel code and debug it quickly:

>>> from joblib import Parallel, delayed
>>> from math import sqrt
>>> Parallel(n_jobs=1)(delayed(sqrt)(i**2) for i in range(10))
[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
Fast compressed Persistence: a replacement for pickle to work efficiently on Python objects containing large data ( joblib.dump & joblib.load ).